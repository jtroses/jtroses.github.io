---
title: "Regression"
author: "Janelle Rose"
date: now
categories: 
  - Regression
  - Multilinear Regression
  - Random Forest
---

This blog post will compare a multilinear regression model to a random forest regression model to predict the salary of an individual based on years of experience and age. This model will create a train test split similar to what was done in the classification model [blog post](https://jtroses.github.io/posts/classification/). 

# Data
```{python}
import pandas as pd
salary = pd.read_csv('../../data/Salary.csv')
salary.info()
```

## Create Train Test split

The dependent/predicted variable is salary. The independent variables for the regression model is years of experience and age. 
```{python}
from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(salary, test_size=0.2, random_state = 35)
```

**Training Set**
```{python}
X_train = train_set[['Years of Experience', 'Age']]
y_train =  train_set['Salary']
```

**Test variables**

```{python}
X_test = test_set[['Years of Experience', 'Age']]
y_test = test_set['Salary']
```

# Visualizations

Scatter plot of the independent variables (Years of Experience and Age) against the dependent variable salary.  
```{python}
import matplotlib.pyplot as plt
X1 = X_train['Years of Experience']
X2 = X_train['Age']
plt.scatter(X1, y_train)
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()
plt.scatter(X2, y_train)
plt.xlabel('Age')
plt.ylabel('Salary')
plt.show()
```

# Linear regression

```{python}
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
salary_predictions = lin_reg.predict(X_train)
salary_predictions
```

## Linear Regression Performace metric RMSE

Root mean squared error, RMSE, can be used to evaluate the model. 

```{python}
from sklearn.metrics import mean_squared_error
lin_rmse = mean_squared_error(y_train, salary_predictions, squared = False)
lin_rmse
```

The RMSE shows that the predicted value from the linear model may be off by $30,187 in either direction. 

## Visualize Linear regression model 

```{python}
import numpy as np
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection = '3d')

ax.scatter3D(
    X1,
    X2,
    y_train,
)

ax.set_xlabel("Years of Experience")
ax.set_ylabel("Age")
ax.set_zlabel("Salary")

xs = np.tile(np.arange(61), (61,1))
ys = np.tile(np.arange(61), (61,1)).T
zs = xs*lin_reg.coef_[0]+ys*lin_reg.coef_[1]+lin_reg.intercept_
ax.plot_surface(xs,ys,zs, alpha=0.5)
plt.show()
```

# Random Forest Regression Model
Run an random forest model with 100 trees.

```{python}
from sklearn.ensemble import RandomForestRegressor
rf_reg = RandomForestRegressor(n_estimators=100,
                                  random_state=42)
rf_reg.fit(X_train, y_train)
rf_salary_pred = rf_reg.predict(X_train)
rf_salary_pred
```

### t_train
```{python}
y_train
```
## Random Forest regression model performance metrics 

```{python}
rf_rmse = mean_squared_error(y_train, rf_salary_pred, squared = False)
rf_rmse
```

The RMSE shows that the predicted value from the linear model may be off by $20,080 in either direction. 

## Visualize a decision tree with a smaller tree

```{python}
from sklearn.tree import export_graphviz
from graphviz import Source
import pydot

rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state = 42)
rf_small.fit(X_train, y_train)
small_tree = rf_small.estimators_[5]
export_graphviz(small_tree, out_file ='small_tree.dot', feature_names = X_train.columns, rounded = True, precision = 1)
Source.from_file("small_tree.dot")
```

**Walk through example decision tree with observation**
```{python}
X_train.iloc[0], y_train.iloc[0]
```

In the example the root starts with `Year of Expereince` <= 5.5, so we would follow the **False** response down the right side of the tree. The next level looks at `Year of Expereince` <= 10.5, again we would follow the **False** response down the right side of the tree. Finally, the tree checks `Year of Expereince` <= 15.5 to which we would respond **True** and the salary for Age 42 with 13 years of experience is predicted to be $157,427.60. The actual salary is $197,000.00.

## Evaluate Test set 
The random forest model does a better job at predicting salay of an individual with a root mean square error of $20,080. So we will evalute the test set with the random forest model. 

```{python}
y_test_predicted = rf_reg.predict(X_test)
rf_test_rmse = mean_squared_error(y_test, y_test_predicted, squared = False)
rf_test_rmse
```

The test set has a similar RMSE to the training set. 